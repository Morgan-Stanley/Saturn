package com.ms.qaTools.kronus.rfb.AkkaStreamTest

include com.ms.qaTools.kronus.rfb.PRELUDE

import scala.concurrent.Future
import com.ms.qaTools.io.rowSource.ColumnDefinition

type Writer = java.io.Writer

type DeviceIO          = com.ms.qaTools.io.DeviceIO
type ExcelIO           = com.ms.qaTools.io.ExcelIO
type ColumnDefinitions = com.ms.qaTools.io.rowSource.ColumnDefinitions

type Row      = Seq[String]
type Rows     = Iterator[$Row] with com.ms.qaTools.io.rowSource.ColumnDefinitions

type Json     = com.fasterxml.jackson.databind.JsonNode
type Jsons    = Iterator[Json]

type Strings  = Iterator[String]

type Document = org.w3c.dom.Document
type Documents = Iterator[Document]

type DsInput  = com.ms.qaTools.io.Input[$Rows]
type DsWriter = com.ms.qaTools.io.Writer[$Rows]
type DsOutput = com.ms.qaTools.io.Output[$DsWriter]
type DsIO     = $DsInput with $DsOutput

type Input[ROW_TYPE]  = com.ms.qaTools.io.Input[ROW_TYPE]
type Output[ROW_TYPE] = com.ms.qaTools.io.Output[com.ms.qaTools.io.Writer[ROW_TYPE]]
type IO[ROW_TYPE]     = $Input[ROW_TYPE] with $Output[ROW_TYPE]

type RowSink   = GraphMeta[akka.stream.SinkShape[Row],     Future[Int], $ColumnDefinitions]
type RowFlow   = GraphMeta[akka.stream.FlowShape[Row, Row],        Any, $ColumnDefinitions]
type RowSource = GraphMeta[akka.stream.SourceShape[Row],           Any, $ColumnDefinitions]

// Stream
def #StreamNode(in:String, inType:String, out:String, outType:String, materializedType:String, name:String)

// kronus graph
def #Edge(color:String, width:Any)
def #Node()
def #Description(message:String)

def StdOut():DeviceIO                  = generate("yield") { com.ms.qaTools.io.StandardIO()       }
def StdErr():DeviceIO                  = generate("yield") { com.ms.qaTools.io.StandardIO(true)   }
def ExcelIO(fileName:String):DeviceIO  = generate("yield") { com.ms.qaTools.io.ExcelIO(fileName)  }
def FileIO(fileName:String):DeviceIO   = generate("yield") { com.ms.qaTools.io.FileIO(fileName)   }
def StringIO(contents:String):DeviceIO = generate("yield") { com.ms.qaTools.io.StringIO(contents) }

def CsvIO(device:DeviceIO):DsIO                   = generate("yield") { com.ms.qaTools.io.definition.CsvIO(device)             }
def DataIO(device:DeviceIO):DsIO                  = generate("yield") { com.ms.qaTools.io.definition.DataIO(device)            }
def ExcelWsIO(device:ExcelIO, wsName:String):DsIO = generate("yield") { com.ms.qaTools.io.definition.ExcelWsIO(device, wsName) }

def JsonIO(device:DeviceIO):IO[Jsons]   = generate("yield") { com.ms.qaTools.io.definition.JsonIO(device) }
def LineIO(device:DeviceIO):IO[Strings] = generate("yield") { com.ms.qaTools.io.definition.LineIO(device) }

def CsvFileIO(fileName:String):DsIO   = { return CsvIO(FileIO(fileName)) }
def CsvInlineIO(fileName:String):DsIO = { return CsvIO(StringIO(fileName)) }

#Edge(color="#000000", width="1")
def DsInput(io:DsIO):Rows = generate("for") { for{ io <- io;  rows = io.input.get } yield rows }

#Edge(color="#ffffff", width="1")
def DsOutput(io:DsIO):DsWriter = generate("for") { for{ io <- io;  writer = io.output.get } yield writer }

#StreamNode(out="out", outType="Row")
def DsSource(io:DsIO): RowSource = generate("yield") {
  val rows = io.input.getOrElse(throw new Exception("An exception occurred in DsSource opening source for Input"))
  GraphMeta(akka.stream.scaladsl.Source.fromIterator { () => rows }, rows)
}

#StreamNode(out="in", inType="Row", out="out", outType="Row", name="")
def DsSelect(in:ColumnDefinitions, colNames:String*): RowFlow = generate("yield") {
  val newColDefs = new com.ms.qaTools.io.rowSource.ColumnDefinitions {
    def colDefs = Seq(in.colDefs(0), in.colDefs(2))
  }
  GraphMeta(akka.stream.scaladsl.Flow[Row].map(r => Seq(r(0), r(2))), newColDefs)
}

#StreamNode(out="in", inType="Row", out="out", outType="Row")
def DsFilter(in:ColumnDefinitions): RowFlow = generate("yield") {
  GraphMeta(akka.stream.scaladsl.Flow[Row].filter(r => r(0) != "20"), in)
}

#StreamNode(in="in", inType="Row", out="left,right", outType="Row")
def DsBalance(in:ColumnDefinitions):ColumnDefinitions = generate("yield") { ??? }

#StreamNode(in="in", inType="Row", materializedType="Int")
def DsWrite(in: ColumnDefinitions, out: Writer): RowSink = generate("yield") {
  val w = new java.io.PrintWriter(out)
  w.println(in.colDefs.map(_.name).mkString(","))
  GraphMeta(akka.stream.scaladsl.Sink.fold[Int,Row](0) { (i, r) =>
    w.println(r.mkString(","))
    i + 1
  }, in)
}

def OUTPUT(): Writer = generate("yield") { new java.io.StringWriter }
def VALIDATE_OUTPUT(w: Writer, expected: String): Unit = generate("yield") {
  assert(w.toString.lines.toSeq == expected.lines.toSeq, w.toString)
}

val OUTPUT_0 = OUTPUT()
val OUTPUT_1 = OUTPUT()
val OUTPUT_2 = OUTPUT()
val TOTAL = SINK0 + SINK1 + SINK2
val VALIDATE = AFTER(TOTAL, {
  val VALIDATE_TOTAL = ASSERT_EQUAL(TOTAL, 8)
  val VALIDATE_OUTPUT_0 = VALIDATE_OUTPUT(OUTPUT_0, "c0,c1,c2
10,11,12
20,21,22
30,31,32")
  val VALIDATE_OUTPUT_1 = VALIDATE_OUTPUT(OUTPUT_1, "c0,c2
10,12
20,22
30,32")
  val VALIDATE_OUTPUT_2 = VALIDATE_OUTPUT(OUTPUT_2, "c0,c2
10,12
30,32")
})

//=-= g1 =-=
val InFileIO  = CsvInlineIO("c0,c1,c2
10,11,12
20,21,22
30,31,32
")

val SOURCE = DsSource(io = InFileIO)
val SELECT = DsSelect(in = SOURCE, colNames = ["C2","C1","C0"])
val FILTER = DsFilter(in = SELECT)
val SINK0  = DsWrite( in = SOURCE, out = OUTPUT_0)
val SINK1  = DsWrite( in = SELECT, out = OUTPUT_1)
val SINK2  = DsWrite( in = FILTER, out = OUTPUT_2)

SELECT <~ SOURCE
FILTER <~ SELECT
SINK0  <~ SOURCE
SINK1  <~ SELECT
FILTER ~> SINK2

def Println(m:String):Unit = generate("yield") { println(m) }

//val SOURCE0 = DsSource(io = InFileIO)
//val SELECT0 = DsSelect(in = SOURCE0, colNames = ["C2","C1","C0"])
//val FILTER0 = DsFilter(in = SELECT0)
//val SINK00  = DsWrite( in = SOURCE0, out = OutFileIO)
//
//def Println(message:String):Unit = generate("yield"){ println(message) }
//val P = Println(SINK00)

//val G2 = {
//  val SOURCE2   = DsSource(io = InFileIO)
//  val BALANCE0  = DsBalance(in = SOURCE2)
//  val BALANCE00 = DsBalance(in = BALANCE0.left)
//  val BALANCE01 = DsBalance(in = BALANCE0.right)
//
//  val SINK00L = DsWrite(in = BALANCE00.left,  out = CsvFileIO("00l.csv"))
//  val SINK00R = DsWrite(in = BALANCE00.right, out = CsvFileIO("00r.csv"))
//  val SINK01L = DsWrite(in = BALANCE01.left,  out = CsvFileIO("01l.csv"))
//  val SINK01R = DsWrite(in = BALANCE01.right, out = CsvFileIO("01r.csv"))
//}
/*
Copyright 2017 Morgan Stanley

Licensed under the GNU Lesser General Public License Version 3 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https://www.gnu.org/licenses/lgpl-3.0.en.html

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

IN ADDITION, THE FOLLOWING DISCLAIMER APPLIES IN CONNECTION WITH THIS PROGRAM:

THIS SOFTWARE IS LICENSED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE AND ANY
WARRANTY OF NON-INFRINGEMENT, ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
OF SUCH DAMAGE. THIS SOFTWARE MAY BE REDISTRIBUTED TO OTHERS ONLY BY EFFECTIVELY
USING THIS OR ANOTHER EQUIVALENT DISCLAIMER IN ADDITION TO ANY OTHER REQUIRED
LICENSE TERMS.
*/
